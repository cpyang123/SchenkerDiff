{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:05:56.846508Z",
     "start_time": "2025-06-22T14:05:56.824192Z"
    }
   },
   "outputs": [],
   "source": [
    "import graph_tool as gt\n",
    "import os\n",
    "import pathlib\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.warnings import PossibleUserWarning\n",
    "from src.diffusion import diffusion_utils\n",
    "\n",
    "import src.utils\n",
    "from src.metrics.abstract_metrics import TrainAbstractMetricsDiscrete, TrainAbstractMetrics\n",
    "\n",
    "from src.diffusion_model import LiftedDenoisingDiffusion\n",
    "from src.diffusion_model_discrete import DiscreteDenoisingDiffusion\n",
    "from src.diffusion.extra_features import DummyExtraFeatures, ExtraFeatures\n",
    "import src.utils\n",
    "from torch_geometric.utils import  to_dense_batch\n",
    "from src.datasets.schenker_dataset import SchenkerDiffHeteroGraphData\n",
    "import torch.nn.functional as F\n",
    "from src.schenker_gnn.config import DEVICE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=PossibleUserWarning)\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:05:39.852631Z",
     "start_time": "2025-06-22T14:05:31.219075Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.distributed as dist\n",
    "\n",
    "# Set environment variables required by the env:// init_method\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "if not dist.is_initialized():\n",
    "    dist.init_process_group(backend=\"gloo\", init_method=\"env://\", rank=0, world_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:05:45.563081Z",
     "start_time": "2025-06-22T14:05:45.082817Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: to-Python converter for std::pair<double, double> already registered; second conversion method ignored.\n"
     ]
    }
   ],
   "source": [
    "from src.datasets.schenker_dataset import SchenkerGraphDataModule, SchenkerDatasetInfos\n",
    "from src.analysis.spectre_utils import PlanarSamplingMetrics, SBMSamplingMetrics, Comm20SamplingMetrics\n",
    "from src.analysis.visualization import NonMolecularVisualization\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Initialize Hydra with the desired config path and version_base\n",
    "with initialize(config_path=\"../SchenkerDiff/configs\", version_base=\"1.3\"):\n",
    "    # Compose the configuration by specifying the config name\n",
    "    cfg = compose(config_name=\"config\")\n",
    "\n",
    "dataset_config = cfg[\"dataset\"]\n",
    "datamodule = SchenkerGraphDataModule(cfg)\n",
    "sampling_metrics = PlanarSamplingMetrics(datamodule)\n",
    "\n",
    "dataset_infos = SchenkerDatasetInfos(datamodule, dataset_config)\n",
    "train_metrics = TrainAbstractMetricsDiscrete() if cfg.model.type == 'discrete' else TrainAbstractMetrics()\n",
    "visualization_tools = NonMolecularVisualization()\n",
    "\n",
    "if cfg.model.type == 'discrete' and cfg.model.extra_features is not None:\n",
    "    extra_features = ExtraFeatures(cfg.model.extra_features, dataset_info=dataset_infos)\n",
    "else:\n",
    "    extra_features = DummyExtraFeatures()\n",
    "domain_features = DummyExtraFeatures()\n",
    "\n",
    "dataset_infos.compute_input_output_dims(datamodule=datamodule, extra_features=extra_features,\n",
    "                                        domain_features=domain_features)\n",
    "\n",
    "model_kwargs = {'dataset_infos': dataset_infos, 'train_metrics': train_metrics,\n",
    "                'sampling_metrics': sampling_metrics, 'visualization_tools': visualization_tools,\n",
    "                'extra_features': extra_features, 'domain_features': domain_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'schenker', 'remove_h': None, 'datadir': 'data/schenker/processed/heterdatacleaned/'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(cfg[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/digress/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal distribution of the classes: tensor([9.9998e-07, 9.9998e-07, 2.0061e-01, 9.9998e-07, 9.9998e-07, 9.9998e-07,\n",
      "        3.1970e-02, 1.5754e-01, 2.7365e-02, 4.5067e-02, 9.0963e-02, 8.3377e-02,\n",
      "        1.7351e-01, 9.9998e-07, 1.4494e-01, 4.4652e-02, 9.9998e-07, 9.9998e-07]) for nodes, tensor([7.5582e-01, 2.8959e-02, 2.8959e-02, 2.2831e-02, 2.2831e-02, 4.7389e-02,\n",
      "        4.0524e-02, 4.0528e-02, 1.1330e-02, 1.5548e-05, 1.5548e-05, 2.8430e-04,\n",
      "        2.3988e-04, 2.3988e-04, 3.5537e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]) for edges\n"
     ]
    }
   ],
   "source": [
    "loaded_model = DiscreteDenoisingDiffusion.load_from_checkpoint(checkpoint_path= \"last-v1.ckpt\", **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/peter/miniconda3/envs/digress/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Run this if you want to fine tune: \n",
    "\n",
    "# name = cfg.general.name\n",
    "# use_gpu = cfg.general.gpus > 0 and torch.cuda.is_available()\n",
    "# datamodule_tune = SchenkerGraphDataModule(cfg, is_tune = True)\n",
    "# trainer = Trainer(gradient_clip_val = cfg.train.clip_grad,\n",
    "#                 strategy = \"ddp_find_unused_parameters_true\",  # Needed to load old checkpoints\n",
    "#                 accelerator = 'gpu' if use_gpu else 'cpu',\n",
    "#                 devices = cfg.general.gpus if use_gpu else 1,\n",
    "#                 max_epochs = cfg.train.n_epochs*2,\n",
    "#                 check_val_every_n_epoch = cfg.general.check_val_every_n_epochs,\n",
    "#                 fast_dev_run = cfg.general.name == 'debug',\n",
    "#                 enable_progress_bar = True,\n",
    "#                 log_every_n_steps = 50 if name != 'debug' else 1,\n",
    "#                 logger = [])\n",
    "\n",
    "# trainer.fit(loaded_model, datamodule = datamodule_tune, ckpt_path = cfg.general.resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "keep_chain = 10\n",
    "number_chain_steps = 99\n",
    "save_final = 10\n",
    "use_rules = True\n",
    "num_nodes=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_r_E(batch_size):\n",
    "    \"\"\"\n",
    "    Samples `batch_size` random pickle files from the directory \n",
    "    where i is a random integer between 0 and 1080. Each pickle file contains a dictionary \n",
    "    that is converted to a PyG Data object using the pre-defined function `hetero_to_data`.\n",
    "    \n",
    "    The PyG Data object is expected to have at least the following attributes:\n",
    "    - x: Tensor of node features with shape (num_nodes, feature_dim)\n",
    "    - edge_index: LongTensor with shape (2, num_edges)\n",
    "    - edge_attr: Tensor with shape (num_edges, 2) representing edge attributes\n",
    "    - r: Tensor with shape (num_nodes, dr) representing additional node-level features\n",
    "    \n",
    "    For each sample, the function creates:\n",
    "    - An adjacency tensor E_sample of shape (n_nodes, n_nodes, 2) where each edge's attribute \n",
    "        is placed at the corresponding (u, v) location. If the original graph has fewer than \n",
    "        `n_nodes` nodes, the tensors are padded with zeros; if it has more, they are truncated.\n",
    "    - A node feature tensor r_sample of shape (n_nodes, dr) similarly padded or truncated.\n",
    "    \n",
    "    Finally, the function stacks these into:\n",
    "    - E_tensor: Tensor of shape (batch_size, n_nodes, n_nodes, 2)\n",
    "    - r_tensor: Tensor of shape (batch_size, n_nodes, dr)\n",
    "    \n",
    "    Returns:\n",
    "        E_tensor, r_tensor\n",
    "    \"\"\"\n",
    "    E_list = []\n",
    "    r_list = []\n",
    "    name_list = []\n",
    "    node_sizes = []\n",
    "\n",
    "    # get samples from OOS distribution\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1780\n",
    "\n",
    "    # Randomly select 90 indices for the test set\n",
    "    test_indices = np.random.choice(n_samples, 200, replace=False)\n",
    "    # test_indices = np.array([1])\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Select a random index between 0 and 1080 (inclusive)\n",
    "        \n",
    "        idx = test_indices[i]\n",
    "        file_path = f\"data/schenker/processed/heterdatacleaned/processed/{idx}_processed.pt\"\n",
    "        \n",
    "        # Load the pickle file containing a dictionary\n",
    "        data_dict = torch.load(file_path)\n",
    "        \n",
    "        # Convert dictionary to a PyG Data object using the provided function\n",
    "        data = SchenkerDiffHeteroGraphData.hetero_to_data(data_dict)\n",
    "        \n",
    "        # Determine the actual number of nodes in the current sample\n",
    "        m = data.x.shape[0]\n",
    "        \n",
    "        \n",
    "        # Initialize an adjacency tensor for this sample\n",
    "        E_sample = torch.zeros((m, m, 30))\n",
    "        # Fill in the edge attributes: iterate over each edge\n",
    "        for i in range(data.edge_index.shape[1]):\n",
    "            u = data.edge_index[0, i].item()\n",
    "            v = data.edge_index[1, i].item()\n",
    "            # Only consider nodes within the allowed range (pad/truncate as needed)\n",
    "            if u < m and v < m:\n",
    "                E_sample[u, v, :] = data.edge_attr[i, :]\n",
    "                \n",
    "        # Process the r tensor (node-level additional features)\n",
    "        dr = data.r.shape[1]  # feature dimension of r\n",
    "        r_sample = torch.zeros((m, dr))\n",
    "        # Copy available node features; pad with zeros if necessary or truncate if too many nodes\n",
    "        r_sample[:m, :] = data.r[:m, :]\n",
    "        \n",
    "        # Append this sample's results to the lists\n",
    "        E_list.append(E_sample)\n",
    "        r_list.append(r_sample)\n",
    "        name_list.append(data_dict['name'])\n",
    "        node_sizes.append(m)\n",
    "    \n",
    "    # Stack all samples to form the batch tensors\n",
    "    # Determine the maximum number of nodes in the batch\n",
    "    max_nodes = max(tensor.shape[0] for tensor in r_list)\n",
    "\n",
    "    # Pad the E_list tensors to shape (max_nodes, max_nodes, 3)\n",
    "    E_padded = []\n",
    "    for e in E_list:\n",
    "        n = e.shape[0]\n",
    "        # F.pad expects pad in the format: (pad_last_dim_left, pad_last_dim_right,\n",
    "        # pad_second_last_dim_left, pad_second_last_dim_right, ...)\n",
    "        # For a tensor of shape (n, n, 3): pad last dimension (3) with (0,0),\n",
    "        # second dimension with (0, max_nodes-n), and first dimension with (0, max_nodes-n).\n",
    "        pad_amount = (0, 0, 0, max_nodes - n, 0, max_nodes - n)\n",
    "        E_padded.append(F.pad(e, pad_amount))\n",
    "\n",
    "    # Stack the padded tensors along a new batch dimension\n",
    "    E_tensor = torch.stack(E_padded, dim=0)  # Shape: (batch_size, max_nodes, max_nodes, 3)\n",
    "\n",
    "    # Pad the r_list tensors to shape (max_nodes, dr)\n",
    "    r_padded = []\n",
    "    for r in r_list:\n",
    "        n = r.shape[0]\n",
    "        # For a tensor of shape (n, dr), pad the first dimension with (0, max_nodes-n)\n",
    "        pad_amount = (0, 0, 0, max_nodes - n)\n",
    "        r_padded.append(F.pad(r, pad_amount))\n",
    "\n",
    "    # Stack the padded tensors along the batch dimension\n",
    "    r_tensor = torch.stack(r_padded, dim=0)  # Shape: (batch_size, max_nodes, dr)\n",
    "    \n",
    "    return E_tensor, r_tensor, name_list, node_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diff_depth_1 = 100\n",
    "num_diff_depth_2 = 100\n",
    "num_diff_depth_3 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 37, 37, 30])\n",
      "[-30, -44, -42, -36, -37, -46, -35, -27]\n",
      "[-32, -33, -33, -34, -29, -37, -35, -39]\n",
      "[-35, -34, -35, -31, -37, -35, -33, -23]\n",
      "[-21, -26, -37, -21, -29, -29, -40, -35]\n",
      "[-28, -39, -35, -23, -31, -29, -26, -35]\n",
      "[-32, -38, -27, -39, -26, -25, -25, -22]\n",
      "[-40, -33, -34, -31, -35, -32, -36, -38]\n",
      "[-30, -40, -18, -39, -31, -40, -28, -39]\n",
      "[-43, -31, -32, -36, -34, -40, -25, -37]\n",
      "[-28, -52, -42, -38, -33, -40, -41, -43]\n",
      "[-29, -41, -34, -26, -30, -38, -31, -25]\n",
      "[-34, -28, -32, -40, -33, -23, -26, -23]\n",
      "[-30, -36, -39, -36, -46, -30, -39, -38]\n",
      "[-31, -27, -29, -42, -25, -38, -46, -20]\n",
      "[-33, -43, -23, -27, -37, -35, -26, -34]\n",
      "[-36, -40, -32, -39, -43, -33, -31, -47]\n",
      "[-41, -27, -26, -31, -41, -38, -32, -31]\n",
      "[-39, -28, -35, -31, -31, -36, -36, -41]\n",
      "[-29, -37, -34, -27, -33, -33, -47, -30]\n",
      "[-34, -35, -36, -27, -33, -41, -34, -38]\n",
      "[-32, -34, -24, -29, -31, -31, -31, -24]\n",
      "[-31, -27, -37, -34, -34, -21, -28, -26]\n",
      "[-37, -25, -34, -30, -37, -25, -32, -34]\n",
      "[-22, -32, -45, -36, -43, -38, -39, -25]\n",
      "[-24, -26, -42, -41, -44, -36, -31, -31]\n",
      "[-29, -28, -37, -24, -33, -37, -28, -32]\n",
      "[-28, -32, -29, -32, -37, -33, -28, -25]\n",
      "[-23, -31, -33, -30, -22, -35, -31, -39]\n",
      "[-30, -27, -27, -29, -40, -29, -26, -25]\n",
      "[-27, -37, -31, -19, -20, -20, -31, -36]\n",
      "[-35, -29, -27, -26, -28, -25, -31, -29]\n",
      "[-41, -30, -26, -36, -25, -25, -28, -33]\n",
      "[-26, -38, -27, -34, -37, -28, -22, -27]\n",
      "[-37, -29, -24, -33, -22, -27, -39, -31]\n",
      "[-24, -20, -26, -24, -26, -30, -33, -32]\n",
      "[-26, -35, -26, -29, -18, -27, -30, -32]\n",
      "[-29, -27, -23, -30, -33, -36, -28, -23]\n",
      "[-33, -30, -26, -23, -26, -33, -28, -26]\n",
      "[-23, -41, -37, -33, -30, -30, -34, -32]\n",
      "[-21, -22, -36, -35, -31, -36, -22, -30]\n",
      "[-29, -32, -29, -27, -30, -24, -30, -31]\n",
      "[-40, -27, -21, -29, -37, -32, -32, -25]\n",
      "[-26, -32, -25, -32, -29, -24, -33, -38]\n",
      "[-31, -34, -27, -33, -32, -24, -29, -42]\n",
      "[-25, -31, -22, -46, -32, -34, -35, -26]\n",
      "[-24, -34, -30, -30, -39, -23, -38, -30]\n",
      "[-26, -31, -29, -26, -26, -30, -28, -30]\n",
      "[-31, -24, -30, -32, -32, -33, -38, -31]\n",
      "[-35, -26, -31, -33, -35, -35, -24, -32]\n",
      "[-30, -26, -31, -29, -36, -25, -32, -29]\n",
      "[-22, -37, -21, -32, -33, -22, -28, -29]\n",
      "[-23, -31, -32, -28, -30, -33, -36, -29]\n",
      "[-34, -33, -27, -29, -23, -23, -31, -33]\n",
      "[-37, -26, -23, -31, -31, -22, -28, -24]\n",
      "[-30, -26, -30, -20, -27, -24, -21, -26]\n",
      "[-34, -23, -29, -19, -23, -27, -29, -23]\n",
      "[-29, -32, -28, -25, -22, -35, -18, -29]\n",
      "[-29, -26, -32, -29, -22, -28, -29, -29]\n",
      "[-25, -32, -38, -33, -31, -30, -25, -30]\n",
      "[-38, -21, -35, -22, -26, -26, -30, -23]\n",
      "[-35, -27, -28, -28, -32, -30, -24, -26]\n",
      "[-28, -25, -27, -32, -30, -30, -31, -24]\n",
      "[-32, -28, -26, -30, -26, -25, -22, -22]\n",
      "[-29, -26, -29, -34, -27, -26, -29, -32]\n",
      "[-26, -29, -23, -34, -34, -25, -22, -25]\n",
      "[-39, -26, -34, -27, -26, -38, -27, -30]\n",
      "[-22, -27, -33, -26, -28, -23, -29, -36]\n",
      "[-29, -24, -30, -25, -25, -30, -22, -31]\n",
      "[-24, -28, -29, -28, -35, -31, -28, -23]\n",
      "[-25, -24, -29, -29, -29, -25, -29, -23]\n",
      "[-29, -25, -23, -20, -28, -23, -35, -23]\n",
      "[-32, -32, -24, -26, -21, -24, -23, -22]\n",
      "[-24, -25, -33, -27, -17, -38, -30, -27]\n",
      "[-26, -23, -25, -21, -28, -31, -32, -28]\n",
      "[-33, -29, -30, -32, -19, -31, -23, -26]\n",
      "[-32, -18, -31, -22, -32, -29, -33, -26]\n",
      "[-26, -31, -23, -18, -27, -34, -23, -32]\n",
      "[-20, -20, -20, -32, -17, -22, -25, -16]\n",
      "[-26, -23, -21, -18, -24, -28, -25, -26]\n",
      "[-18, -22, -23, -23, -19, -23, -23, -22]\n",
      "[-23, -22, -32, -28, -15, -21, -21, -23]\n",
      "[-16, -24, -24, -20, -27, -33, -25, -22]\n",
      "[-27, -23, -19, -20, -20, -26, -24, -16]\n",
      "[-19, -29, -18, -23, -26, -18, -25, -26]\n",
      "[-21, -27, -19, -28, -21, -22, -26, -23]\n",
      "[-29, -18, -19, -19, -18, -27, -19, -18]\n",
      "[-27, -17, -29, -22, -22, -28, -22, -23]\n",
      "[-21, -26, -24, -25, -20, -24, -32, -21]\n",
      "[-23, -22, -26, -20, -23, -32, -28, -16]\n",
      "[-23, -20, -25, -25, -22, -24, -24, -25]\n",
      "[-23, -21, -24, -20, -16, -23, -17, -13]\n",
      "[-24, -27, -23, -23, -25, -20, -31, -23]\n",
      "[-21, -30, -24, -22, -27, -25, -21, -27]\n",
      "[-22, -26, -23, -13, -27, -19, -23, -23]\n",
      "[-21, -26, -25, -26, -17, -21, -26, -24]\n",
      "[-26, -24, -26, -25, -28, -26, -16, -23]\n",
      "[-22, -21, -21, -16, -19, -23, -21, -27]\n",
      "[-18, -17, -22, -18, -19, -21, -17, -20]\n",
      "[-24, -19, -20, -18, -14, -13, -22, -16]\n",
      "[-21, -16, -20, -28, -15, -19, -18, -26]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    ":param batch_id: int\n",
    ":param batch_size: int\n",
    ":param num_nodes: int, <int>tensor (batch_size) (optional) for specifying number of nodes\n",
    ":param save_final: int: number of predictions to save to file\n",
    ":param keep_chain: int: number of chains to save to file\n",
    ":param keep_chain_steps: number of timesteps to save for each chain\n",
    ":return: molecule_list. Each element of this list is a tuple (atom_types, charges, positions)\n",
    "\"\"\"\n",
    "E, r, names, n_nodes_list = sample_r_E(batch_size)\n",
    "print(E.shape)\n",
    "num_nodes = torch.tensor([int(x) for x in n_nodes_list]).to(loaded_model.device)\n",
    "if num_nodes is None:\n",
    "    n_nodes = loaded_model.node_dist.sample_n(batch_size, loaded_model.device)\n",
    "elif type(num_nodes) == int:\n",
    "    n_nodes = num_nodes * torch.ones(batch_size, device=loaded_model.device, dtype=torch.int)\n",
    "else:\n",
    "    assert isinstance(num_nodes, torch.Tensor)\n",
    "    n_nodes = num_nodes\n",
    "n_max = torch.max(n_nodes).item()\n",
    "# Build the masks\n",
    "arange = torch.arange(n_max, device=loaded_model.device).unsqueeze(0).expand(batch_size, -1)\n",
    "node_mask = arange < n_nodes.unsqueeze(1)\n",
    "\n",
    "# Sample a piece, and use the R matrix from that\n",
    "# Get a random sample from the data\n",
    "# pass through Stephen's script to get the S matrix, and the R matrix through the data processing (process_file_for_GUI)\n",
    "\n",
    "# Sample noise  -- z has size (n_samples, n_nodes, n_features)\n",
    "z_T = diffusion_utils.sample_discrete_feature_noise(limit_dist=loaded_model.limit_dist, node_mask=node_mask)\n",
    "X, _, y = z_T.X, z_T.E, z_T.y\n",
    "\n",
    "E_transpose = E.permute(0, 2, 1, 3)  # Shape remains (bs, n_nodes, n_nodes, 2)\n",
    "\n",
    "# Symmetrize using max operation (ensures strongest connection remains)\n",
    "E = torch.maximum(E, E_transpose).to(DEVICE)     \n",
    "r = r.to(DEVICE)\n",
    "\n",
    "assert (E == torch.transpose(E, 1, 2)).all()\n",
    "assert number_chain_steps < loaded_model.T\n",
    "chain_X_size = torch.Size((number_chain_steps, keep_chain, X.size(1)))\n",
    "chain_E_size = torch.Size((number_chain_steps, keep_chain, E.size(1), E.size(2)))\n",
    "\n",
    "chain_X = torch.zeros(chain_X_size)\n",
    "chain_E = torch.zeros(chain_E_size)\n",
    "\n",
    "# Iteratively sample p(z_s | z_t) for t = 1, ..., T, with s = t - 1.\n",
    "for s_int in reversed(range(0, loaded_model.T)):\n",
    "    s_array = s_int * torch.ones((batch_size, 1)).type_as(y)\n",
    "    t_array = s_array + 1\n",
    "    s_norm = s_array / loaded_model.T\n",
    "    t_norm = t_array / loaded_model.T\n",
    "\n",
    "    # Sample z_s\n",
    "    if use_rules:\n",
    "        sampled_s, discrete_sampled_s = loaded_model.sample_p_zs_given_zt_with_rules(s_norm, t_norm, X, E, r, y, node_mask)\n",
    "    else:\n",
    "        sampled_s, discrete_sampled_s = loaded_model.sample_p_zs_given_zt(s_norm, t_norm, X, E, r, y, node_mask)\n",
    "\n",
    "    X, _, y = sampled_s.X, sampled_s.E, sampled_s.y\n",
    "\n",
    "    discrete_sampled_s_E, _ = loaded_model.apply_node_mask_E_r(E,r, node_mask)\n",
    "    \n",
    "    # Save the first keep_chain graphs\n",
    "    write_index = (s_int * number_chain_steps) // loaded_model.T\n",
    "    chain_X[write_index] = discrete_sampled_s.X[:keep_chain]\n",
    "    chain_E[write_index] = discrete_sampled_s_E[:keep_chain]\n",
    "\n",
    "\n",
    "# # Sample\n",
    "sampled_s = sampled_s.mask(node_mask, collapse=True)\n",
    "\n",
    "# unique_depths = sorted({int(d.item()) for d in torch.unique(r[:, :, -1])}, reverse=True)\n",
    "\n",
    "# # We'll accumulate updates into these tensors\n",
    "# X_acc = X.clone()\n",
    "# E_acc = E.clone()\n",
    "# r_acc = r.clone()\n",
    "\n",
    "\n",
    "# for depth in unique_depths:\n",
    "#     steps = 200\n",
    "#     # Build a mask of nodes at exactly this structural depth\n",
    "#     depth_mask = (r_acc[:, :, -1] >= depth)\n",
    "\n",
    "#     # print(depth_mask.shape)\n",
    "#     # print(node_mask.shape)\n",
    "#     depth_mask = depth_mask & node_mask\n",
    "#     if not depth_mask.any():\n",
    "#         continue\n",
    "\n",
    "#     # Extract the subgraph at this depth\n",
    "#     # apply_node_mask_E_r will zero out everything except the masked nodes & edges\n",
    "#     # E_sub, r_sub = loaded_model.apply_node_mask_E_r(E_acc, r_acc, depth_mask)\n",
    "#     # X_sub = X_acc.clone()\n",
    "#     X_sub = X.clone()\n",
    "#     E_sub = E.clone()\n",
    "#     r_sub = r.clone()\n",
    "\n",
    "\n",
    "#     # Run diffusion on this subgraph for `steps` timesteps\n",
    "#     for s_int in reversed(range(0, loaded_model.T)):\n",
    "#         s_array = s_int * torch.ones((batch_size, 1)).type_as(y)\n",
    "#         t_array = s_array + 1\n",
    "#         s_norm = s_array / loaded_model.T\n",
    "#         t_norm = t_array / loaded_model.T\n",
    "#         # print(E_sub.shape)\n",
    "#         sampled_sub, _ = loaded_model.sample_p_zs_given_zt(\n",
    "#             s_norm, t_norm, X_sub, E_sub, r_sub, y, depth_mask\n",
    "#         )\n",
    "#         # Unpack the results\n",
    "#         X_sub = sampled_sub.X\n",
    "#         discrete_sampled_s_E, _ = loaded_model.apply_node_mask_E_r(E_sub, r_sub, depth_mask)\n",
    "\n",
    "#     # Integrate the updated subgraph back into the full graph\n",
    "#     # Update node features\n",
    "#     print( X_acc[depth_mask].shape)\n",
    "#     print(X_sub[depth_mask].shape)\n",
    "\n",
    "#     # ensure both sides are floats\n",
    "#     X_sub = X_sub.to(X_acc.dtype)\n",
    "#     X_acc[depth_mask] = X_sub[depth_mask]\n",
    "\n",
    "#     # and likewise for E_sub/E_acc\n",
    "#     E_sub = E_sub.to(E_acc.dtype)\n",
    "#     E_acc[:, depth_mask.squeeze(), :][:, :, depth_mask.squeeze()] = E_sub[:, depth_mask.squeeze(), :][:, :, depth_mask.squeeze()]\n",
    "\n",
    "\n",
    "#     # X_acc[depth_mask] = X_sub[depth_mask]\n",
    "#     # Update edges among these nodes\n",
    "#     # E_acc[:, depth_mask, :][:, :, depth_mask] = E_sub[:, depth_mask, :][:, :, depth_mask]\n",
    "#     # Update rhythm/depth tensor for these nodes\n",
    "#     r_sub = r_sub.to(r_acc.dtype)\n",
    "#     r_acc[depth_mask] = r_sub[depth_mask]\n",
    "\n",
    "# # Replace the originals with the depth‐driven updated versions\n",
    "# X, E, r = X_acc, E_acc, r_acc\n",
    "\n",
    "\n",
    "# sampled_s = sampled_sub.mask(depth_mask, collapse=True)\n",
    "\n",
    "# --- End of structural‐depth‐driven block ---\n",
    "\n",
    "\n",
    "#[TODO] replace the sampling loop above with the following:\n",
    "# Also remember to implement dataprocessing and the model such that it can take in depth information d\n",
    "\n",
    "# For each sampled piece with noisy nodes:\n",
    "# For each edge type of depth d, itterating from max(d) to min(d)\n",
    "\n",
    "# 1. Get only the nodes that are connected by structural edges of depth d from the last column of the R tensor\n",
    "# 2. Use it to create a noisy subgraph defined by X', E', R'. If X', E', R' already exists, append the new nodes and edges to it\n",
    "# 3. Feed X', E', R' into the Diffusion model with num_diff_step_d steps\n",
    "# 4. Save the resulting graph as X', E', R'\n",
    "# 5. Repeat until all nodes and edges in the original graph has been added\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, _, y = sampled_s.X, sampled_s.E, sampled_s.y\n",
    "\n",
    "E, _ = loaded_model.apply_node_mask_E_r(E,r, node_mask)\n",
    "\n",
    "# Prepare the chain for saving\n",
    "if keep_chain > 0:\n",
    "    final_X_chain = X[:keep_chain]\n",
    "    final_E_chain = E[:keep_chain]\n",
    "\n",
    "    chain_X[0] = final_X_chain                  # Overwrite last frame with the resulting X, E\n",
    "    chain_E[0] = final_E_chain\n",
    "\n",
    "    chain_X = diffusion_utils.reverse_tensor(chain_X)\n",
    "    chain_E = diffusion_utils.reverse_tensor(chain_E)\n",
    "\n",
    "    # Repeat last frame to see final sample better\n",
    "    chain_X = torch.cat([chain_X, chain_X[-1:].repeat(10, 1, 1)], dim=0)\n",
    "    chain_E = torch.cat([chain_E, chain_E[-1:].repeat(10, 1, 1, 1)], dim=0)\n",
    "    assert chain_X.size(0) == (number_chain_steps + 10)\n",
    "\n",
    "molecule_list = []\n",
    "for i in range(batch_size):\n",
    "    n = n_nodes[i]\n",
    "    atom_types = X[i, :n].cpu()\n",
    "    edge_types = E[i, :n, :n].cpu()\n",
    "    rhythm_types = r[i, :n, :].cpu()\n",
    "    sample_names = names[i]\n",
    "    molecule_list.append([atom_types, edge_types, rhythm_types, sample_names])\n",
    "\n",
    "# Visualize chains\n",
    "# if loaded_model.visualization_tools is not None:\n",
    "#     loaded_model.print('Visualizing chains...')\n",
    "#     current_path = os.getcwd()\n",
    "#     num_molecules = chain_X.size(1)       # number of molecules\n",
    "#     for i in range(num_molecules):\n",
    "#         result_path = os.path.join(current_path, f'chains/{loaded_model.cfg.general.name}/'\n",
    "#                                                     f'epoch{loaded_model.current_epoch}/')\n",
    "#         if not os.path.exists(result_path):\n",
    "#             os.makedirs(result_path)\n",
    "#             _ = loaded_model.visualization_tools.visualize_chain(result_path,\n",
    "#                                                             chain_X[:, i, :].numpy(),\n",
    "#                                                             chain_E[:, i, :].numpy())\n",
    "#         loaded_model.print('\\r{}/{} complete'.format(i+1, num_molecules), end='', flush=True)\n",
    "#     loaded_model.print('\\nVisualizing molecules...')\n",
    "\n",
    "#     # Visualize the final molecules \n",
    "#     result_path = os.path.join(current_path,\n",
    "#                                 f'graphs/{loaded_model.name}/epoch{loaded_model.current_epoch}/')\n",
    "#     loaded_model.visualization_tools.visualize(result_path, molecule_list, save_final)\n",
    "#     loaded_model.print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(molecule_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated graphs Saved. \n"
     ]
    }
   ],
   "source": [
    "samples = molecule_list\n",
    "filename = f'generated_samples1.txt'\n",
    "\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    for item in samples:\n",
    "        f.write(f\"N={item[0].shape[0]}\\n\")\n",
    "        atoms = item[0].tolist()\n",
    "        f.write(\"X: \\n\")\n",
    "        for at in atoms:\n",
    "            f.write(f\"{at} \")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"E: \\n\")\n",
    "        for bond_list in item[1]:\n",
    "            for bond in bond_list:\n",
    "                f.write(f\"{int(bond)} \")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"R: \\n\")\n",
    "        for r_list in item[2]:\n",
    "            for r in r_list:\n",
    "                f.write(f\"{r} \")\n",
    "            f.write(\"\\n\")\n",
    "        for name in item[3]:\n",
    "            f.write(name)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "print(\"Generated graphs Saved. \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
