{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/miniconda3/envs/digress/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/peter/miniconda3/envs/digress/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import graph_tool as gt\n",
    "import os\n",
    "import pathlib\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.warnings import PossibleUserWarning\n",
    "from src.diffusion import diffusion_utils\n",
    "\n",
    "import src.utils\n",
    "from src.metrics.abstract_metrics import TrainAbstractMetricsDiscrete, TrainAbstractMetrics\n",
    "\n",
    "from src.diffusion_model import LiftedDenoisingDiffusion\n",
    "from src.diffusion_model_discrete import DiscreteDenoisingDiffusion\n",
    "from src.diffusion.extra_features import DummyExtraFeatures, ExtraFeatures\n",
    "import src.utils\n",
    "from torch_geometric.utils import  to_dense_batch\n",
    "from src.datasets.schenker_dataset import SchenkerDiffHeteroGraphData\n",
    "import torch.nn.functional as F\n",
    "from src.schenker_gnn.config import DEVICE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=PossibleUserWarning)\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.distributed as dist\n",
    "\n",
    "# Set environment variables required by the env:// init_method\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "if not dist.is_initialized():\n",
    "    dist.init_process_group(backend=\"gloo\", init_method=\"env://\", rank=0, world_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for std::pair<double, double> already registered; second conversion method ignored.\n"
     ]
    }
   ],
   "source": [
    "from src.datasets.schenker_dataset import SchenkerGraphDataModule, SchenkerDatasetInfos\n",
    "from src.analysis.spectre_utils import PlanarSamplingMetrics, SBMSamplingMetrics, Comm20SamplingMetrics\n",
    "from src.analysis.visualization import NonMolecularVisualization\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Initialize Hydra with the desired config path and version_base\n",
    "with initialize(config_path=\"../SchenkerDiff/configs\", version_base=\"1.3\"):\n",
    "    # Compose the configuration by specifying the config name\n",
    "    cfg = compose(config_name=\"config\")\n",
    "\n",
    "dataset_config = cfg[\"dataset\"]\n",
    "datamodule = SchenkerGraphDataModule(cfg)\n",
    "sampling_metrics = PlanarSamplingMetrics(datamodule)\n",
    "\n",
    "dataset_infos = SchenkerDatasetInfos(datamodule, dataset_config)\n",
    "train_metrics = TrainAbstractMetricsDiscrete() if cfg.model.type == 'discrete' else TrainAbstractMetrics()\n",
    "visualization_tools = NonMolecularVisualization()\n",
    "\n",
    "if cfg.model.type == 'discrete' and cfg.model.extra_features is not None:\n",
    "    extra_features = ExtraFeatures(cfg.model.extra_features, dataset_info=dataset_infos)\n",
    "else:\n",
    "    extra_features = DummyExtraFeatures()\n",
    "domain_features = DummyExtraFeatures()\n",
    "\n",
    "dataset_infos.compute_input_output_dims(datamodule=datamodule, extra_features=extra_features,\n",
    "                                        domain_features=domain_features)\n",
    "\n",
    "model_kwargs = {'dataset_infos': dataset_infos, 'train_metrics': train_metrics,\n",
    "                'sampling_metrics': sampling_metrics, 'visualization_tools': visualization_tools,\n",
    "                'extra_features': extra_features, 'domain_features': domain_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/miniconda3/envs/digress/lib/python3.10/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal distribution of the classes: tensor([2.3084e-03, 9.9998e-07, 1.8443e-01, 1.1088e-04, 4.4510e-03, 1.2032e-02,\n",
      "        6.9781e-03, 1.3405e-01, 1.6581e-04, 9.3890e-02, 2.2075e-04, 1.6113e-01,\n",
      "        1.6053e-01, 9.9998e-07, 9.1033e-02, 1.3240e-01, 1.6263e-02, 9.9998e-07]) for nodes, tensor([0.9779, 0.0182, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) for edges\n"
     ]
    }
   ],
   "source": [
    "loaded_model = DiscreteDenoisingDiffusion.load_from_checkpoint(checkpoint_path= \"last-v1.ckpt\", **model_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/peter/miniconda3/envs/digress/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# Run this if you want to fine tune: \n",
    "\n",
    "# name = cfg.general.name\n",
    "# use_gpu = cfg.general.gpus > 0 and torch.cuda.is_available()\n",
    "# datamodule_tune = SchenkerGraphDataModule(cfg, is_tune = True)\n",
    "# trainer = Trainer(gradient_clip_val = cfg.train.clip_grad,\n",
    "#                 strategy = \"ddp_find_unused_parameters_true\",  # Needed to load old checkpoints\n",
    "#                 accelerator = 'gpu' if use_gpu else 'cpu',\n",
    "#                 devices = cfg.general.gpus if use_gpu else 1,\n",
    "#                 max_epochs = cfg.train.n_epochs*2,\n",
    "#                 check_val_every_n_epoch = cfg.general.check_val_every_n_epochs,\n",
    "#                 fast_dev_run = cfg.general.name == 'debug',\n",
    "#                 enable_progress_bar = True,\n",
    "#                 log_every_n_steps = 50 if name != 'debug' else 1,\n",
    "#                 logger = [])\n",
    "\n",
    "# trainer.fit(loaded_model, datamodule = datamodule_tune, ckpt_path = cfg.general.resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1\n",
    "keep_chain = 10\n",
    "number_chain_steps = 100\n",
    "save_final = 10\n",
    "num_nodes=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_r_E(batch_size):\n",
    "    \"\"\"\n",
    "    Samples `batch_size` random pickle files from the directory \n",
    "    where i is a random integer between 0 and 1080. Each pickle file contains a dictionary \n",
    "    that is converted to a PyG Data object using the pre-defined function `hetero_to_data`.\n",
    "    \n",
    "    The PyG Data object is expected to have at least the following attributes:\n",
    "    - x: Tensor of node features with shape (num_nodes, feature_dim)\n",
    "    - edge_index: LongTensor with shape (2, num_edges)\n",
    "    - edge_attr: Tensor with shape (num_edges, 2) representing edge attributes\n",
    "    - r: Tensor with shape (num_nodes, dr) representing additional node-level features\n",
    "    \n",
    "    For each sample, the function creates:\n",
    "    - An adjacency tensor E_sample of shape (n_nodes, n_nodes, 2) where each edge's attribute \n",
    "        is placed at the corresponding (u, v) location. If the original graph has fewer than \n",
    "        `n_nodes` nodes, the tensors are padded with zeros; if it has more, they are truncated.\n",
    "    - A node feature tensor r_sample of shape (n_nodes, dr) similarly padded or truncated.\n",
    "    \n",
    "    Finally, the function stacks these into:\n",
    "    - E_tensor: Tensor of shape (batch_size, n_nodes, n_nodes, 2)\n",
    "    - r_tensor: Tensor of shape (batch_size, n_nodes, dr)\n",
    "    \n",
    "    Returns:\n",
    "        E_tensor, r_tensor\n",
    "    \"\"\"\n",
    "    E_list = []\n",
    "    r_list = []\n",
    "    name_list = []\n",
    "    node_sizes = []\n",
    "\n",
    "    # get samples from OOS distribution\n",
    "    np.random.seed(42)\n",
    "    n_samples = 76\n",
    "\n",
    "    # Randomly select 90 indices for the test set\n",
    "    # test_indices = np.random.choice(n_samples, 150, replace=False)\n",
    "    test_indices = np.array([1])\n",
    "    \n",
    "    for _ in range(batch_size):\n",
    "        # Select a random index between 0 and 1080 (inclusive)\n",
    "        \n",
    "        idx = 1\n",
    "        file_path = f\"data/schenker/processed/heterdatacleaned/processed/{idx}_processed.pt\"\n",
    "        \n",
    "        # Load the pickle file containing a dictionary\n",
    "        data_dict = torch.load(file_path)\n",
    "        \n",
    "        # Convert dictionary to a PyG Data object using the provided function\n",
    "        data = SchenkerDiffHeteroGraphData.hetero_to_data(data_dict)\n",
    "        \n",
    "        # Determine the actual number of nodes in the current sample\n",
    "        m = data.x.shape[0]\n",
    "        \n",
    "        \n",
    "        # Initialize an adjacency tensor for this sample\n",
    "        E_sample = torch.zeros((m, m, 10))\n",
    "        # Fill in the edge attributes: iterate over each edge\n",
    "        for i in range(data.edge_index.shape[1]):\n",
    "            u = data.edge_index[0, i].item()\n",
    "            v = data.edge_index[1, i].item()\n",
    "            # Only consider nodes within the allowed range (pad/truncate as needed)\n",
    "            if u < m and v < m:\n",
    "                E_sample[u, v, :] = data.edge_attr[i, :]\n",
    "                \n",
    "        # Process the r tensor (node-level additional features)\n",
    "        dr = data.r.shape[1]  # feature dimension of r\n",
    "        r_sample = torch.zeros((m, dr))\n",
    "        # Copy available node features; pad with zeros if necessary or truncate if too many nodes\n",
    "        r_sample[:m, :] = data.r[:m, :]\n",
    "        \n",
    "        # Append this sample's results to the lists\n",
    "        E_list.append(E_sample)\n",
    "        r_list.append(r_sample)\n",
    "        name_list.append(data_dict['name'])\n",
    "        node_sizes.append(m)\n",
    "    \n",
    "    # Stack all samples to form the batch tensors\n",
    "    # Determine the maximum number of nodes in the batch\n",
    "    max_nodes = max(tensor.shape[0] for tensor in r_list)\n",
    "\n",
    "    # Pad the E_list tensors to shape (max_nodes, max_nodes, 3)\n",
    "    E_padded = []\n",
    "    for e in E_list:\n",
    "        n = e.shape[0]\n",
    "        # F.pad expects pad in the format: (pad_last_dim_left, pad_last_dim_right,\n",
    "        # pad_second_last_dim_left, pad_second_last_dim_right, ...)\n",
    "        # For a tensor of shape (n, n, 3): pad last dimension (3) with (0,0),\n",
    "        # second dimension with (0, max_nodes-n), and first dimension with (0, max_nodes-n).\n",
    "        pad_amount = (0, 0, 0, max_nodes - n, 0, max_nodes - n)\n",
    "        E_padded.append(F.pad(e, pad_amount))\n",
    "\n",
    "    # Stack the padded tensors along a new batch dimension\n",
    "    E_tensor = torch.stack(E_padded, dim=0)  # Shape: (batch_size, max_nodes, max_nodes, 3)\n",
    "\n",
    "    # Pad the r_list tensors to shape (max_nodes, dr)\n",
    "    r_padded = []\n",
    "    for r in r_list:\n",
    "        n = r.shape[0]\n",
    "        # For a tensor of shape (n, dr), pad the first dimension with (0, max_nodes-n)\n",
    "        pad_amount = (0, 0, 0, max_nodes - n)\n",
    "        r_padded.append(F.pad(r, pad_amount))\n",
    "\n",
    "    # Stack the padded tensors along the batch dimension\n",
    "    r_tensor = torch.stack(r_padded, dim=0)  # Shape: (batch_size, max_nodes, dr)\n",
    "    \n",
    "    return E_tensor, r_tensor, name_list, node_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diff_depth_1 = 100\n",
    "num_diff_depth_2 = 100\n",
    "num_diff_depth_3 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for dimension 0 with size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m:param batch_id: int\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m:param batch_size: int\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m:return: molecule_list. Each element of this list is a tuple (atom_types, charges, positions)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m E, r, names, n_nodes_list \u001b[38;5;241m=\u001b[39m \u001b[43msample_r_E\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(E\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mint\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m n_nodes_list])\u001b[38;5;241m.\u001b[39mto(loaded_model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[11], line 49\u001b[0m, in \u001b[0;36msample_r_E\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(file_path)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Convert dictionary to a PyG Data object using the provided function\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mSchenkerDiffHeteroGraphData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhetero_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Determine the actual number of nodes in the current sample\u001b[39;00m\n\u001b[1;32m     52\u001b[0m m \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/mnt/c/Users/Peter/OneDrive/Desktop/Duke/Music ML Research/Diffusion/SchenkerDiff/src/datasets/schenker_dataset.py:346\u001b[0m, in \u001b[0;36mSchenkerDiffHeteroGraphData.hetero_to_data\u001b[0;34m(hetero_dict)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# one‐hot for this edge_type\u001b[39;00m\n\u001b[1;32m    345\u001b[0m one_hot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(NUM_EDGE_TYPES)\n\u001b[0;32m--> 346\u001b[0m \u001b[43mone_hot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mone_hot_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# repeat one_hot for each new edge\u001b[39;00m\n\u001b[1;32m    348\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m one_hot\u001b[38;5;241m.\u001b[39mrepeat(filtered_ei\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for dimension 0 with size 15"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    ":param batch_id: int\n",
    ":param batch_size: int\n",
    ":param num_nodes: int, <int>tensor (batch_size) (optional) for specifying number of nodes\n",
    ":param save_final: int: number of predictions to save to file\n",
    ":param keep_chain: int: number of chains to save to file\n",
    ":param keep_chain_steps: number of timesteps to save for each chain\n",
    ":return: molecule_list. Each element of this list is a tuple (atom_types, charges, positions)\n",
    "\"\"\"\n",
    "E, r, names, n_nodes_list = sample_r_E(batch_size)\n",
    "print(E.shape)\n",
    "num_nodes = torch.tensor([int(x) for x in n_nodes_list]).to(loaded_model.device)\n",
    "if num_nodes is None:\n",
    "    n_nodes = loaded_model.node_dist.sample_n(batch_size, loaded_model.device)\n",
    "elif type(num_nodes) == int:\n",
    "    n_nodes = num_nodes * torch.ones(batch_size, device=loaded_model.device, dtype=torch.int)\n",
    "else:\n",
    "    assert isinstance(num_nodes, torch.Tensor)\n",
    "    n_nodes = num_nodes\n",
    "n_max = torch.max(n_nodes).item()\n",
    "# Build the masks\n",
    "arange = torch.arange(n_max, device=loaded_model.device).unsqueeze(0).expand(batch_size, -1)\n",
    "node_mask = arange < n_nodes.unsqueeze(1)\n",
    "\n",
    "# Sample a piece, and use the R matrix from that\n",
    "# Get a random sample from the data\n",
    "# pass through Stephen's script to get the S matrix, and the R matrix through the data processing (process_file_for_GUI)\n",
    "\n",
    "# Sample noise  -- z has size (n_samples, n_nodes, n_features)\n",
    "z_T = diffusion_utils.sample_discrete_feature_noise(limit_dist=loaded_model.limit_dist, node_mask=node_mask)\n",
    "X, _, y = z_T.X, z_T.E, z_T.y\n",
    "\n",
    "E_transpose = E.permute(0, 2, 1, 3)  # Shape remains (bs, n_nodes, n_nodes, 2)\n",
    "\n",
    "# Symmetrize using max operation (ensures strongest connection remains)\n",
    "E = torch.maximum(E, E_transpose).to(DEVICE)     \n",
    "r = r.to(DEVICE)\n",
    "\n",
    "assert (E == torch.transpose(E, 1, 2)).all()\n",
    "assert number_chain_steps < loaded_model.T\n",
    "chain_X_size = torch.Size((number_chain_steps, keep_chain, X.size(1)))\n",
    "chain_E_size = torch.Size((number_chain_steps, keep_chain, E.size(1), E.size(2)))\n",
    "\n",
    "chain_X = torch.zeros(chain_X_size)\n",
    "chain_E = torch.zeros(chain_E_size)\n",
    "\n",
    "# # Iteratively sample p(z_s | z_t) for t = 1, ..., T, with s = t - 1.\n",
    "for s_int in reversed(range(0, loaded_model.T)):\n",
    "    s_array = s_int * torch.ones((batch_size, 1)).type_as(y)\n",
    "    t_array = s_array + 1\n",
    "    s_norm = s_array / loaded_model.T\n",
    "    t_norm = t_array / loaded_model.T\n",
    "\n",
    "    # Sample z_s\n",
    "    sampled_s, discrete_sampled_s = loaded_model.sample_p_zs_given_zt(s_norm, t_norm, X, E, r, y, node_mask)\n",
    "    X, _, y = sampled_s.X, sampled_s.E, sampled_s.y\n",
    "\n",
    "    discrete_sampled_s_E, _ = loaded_model.apply_node_mask_E_r(E,r, node_mask)\n",
    "    # Save the first keep_chain graphs\n",
    "    write_index = (s_int * number_chain_steps) // loaded_model.T\n",
    "    chain_X[write_index] = discrete_sampled_s.X[:keep_chain]\n",
    "    chain_E[write_index] = discrete_sampled_s_E[:keep_chain]\n",
    "\n",
    "\n",
    "# # Sample\n",
    "sampled_s = sampled_s.mask(node_mask, collapse=True)\n",
    "\n",
    "# unique_depths = sorted({int(d.item()) for d in torch.unique(r[:, :, -1])}, reverse=True)\n",
    "\n",
    "# # We'll accumulate updates into these tensors\n",
    "# X_acc = X.clone()\n",
    "# E_acc = E.clone()\n",
    "# r_acc = r.clone()\n",
    "\n",
    "\n",
    "# for depth in unique_depths:\n",
    "#     steps = 200\n",
    "#     # Build a mask of nodes at exactly this structural depth\n",
    "#     depth_mask = (r_acc[:, :, -1] >= depth)\n",
    "\n",
    "#     # print(depth_mask.shape)\n",
    "#     # print(node_mask.shape)\n",
    "#     depth_mask = depth_mask & node_mask\n",
    "#     if not depth_mask.any():\n",
    "#         continue\n",
    "\n",
    "#     # Extract the subgraph at this depth\n",
    "#     # apply_node_mask_E_r will zero out everything except the masked nodes & edges\n",
    "#     # E_sub, r_sub = loaded_model.apply_node_mask_E_r(E_acc, r_acc, depth_mask)\n",
    "#     # X_sub = X_acc.clone()\n",
    "#     X_sub = X.clone()\n",
    "#     E_sub = E.clone()\n",
    "#     r_sub = r.clone()\n",
    "\n",
    "\n",
    "#     # Run diffusion on this subgraph for `steps` timesteps\n",
    "#     for s_int in reversed(range(0, loaded_model.T)):\n",
    "#         s_array = s_int * torch.ones((batch_size, 1)).type_as(y)\n",
    "#         t_array = s_array + 1\n",
    "#         s_norm = s_array / loaded_model.T\n",
    "#         t_norm = t_array / loaded_model.T\n",
    "#         # print(E_sub.shape)\n",
    "#         sampled_sub, _ = loaded_model.sample_p_zs_given_zt(\n",
    "#             s_norm, t_norm, X_sub, E_sub, r_sub, y, depth_mask\n",
    "#         )\n",
    "#         # Unpack the results\n",
    "#         X_sub = sampled_sub.X\n",
    "#         discrete_sampled_s_E, _ = loaded_model.apply_node_mask_E_r(E_sub, r_sub, depth_mask)\n",
    "\n",
    "#     # Integrate the updated subgraph back into the full graph\n",
    "#     # Update node features\n",
    "#     print( X_acc[depth_mask].shape)\n",
    "#     print(X_sub[depth_mask].shape)\n",
    "\n",
    "#     # ensure both sides are floats\n",
    "#     X_sub = X_sub.to(X_acc.dtype)\n",
    "#     X_acc[depth_mask] = X_sub[depth_mask]\n",
    "\n",
    "#     # and likewise for E_sub/E_acc\n",
    "#     E_sub = E_sub.to(E_acc.dtype)\n",
    "#     E_acc[:, depth_mask.squeeze(), :][:, :, depth_mask.squeeze()] = E_sub[:, depth_mask.squeeze(), :][:, :, depth_mask.squeeze()]\n",
    "\n",
    "\n",
    "#     # X_acc[depth_mask] = X_sub[depth_mask]\n",
    "#     # Update edges among these nodes\n",
    "#     # E_acc[:, depth_mask, :][:, :, depth_mask] = E_sub[:, depth_mask, :][:, :, depth_mask]\n",
    "#     # Update rhythm/depth tensor for these nodes\n",
    "#     r_sub = r_sub.to(r_acc.dtype)\n",
    "#     r_acc[depth_mask] = r_sub[depth_mask]\n",
    "\n",
    "# # Replace the originals with the depth‐driven updated versions\n",
    "# X, E, r = X_acc, E_acc, r_acc\n",
    "\n",
    "\n",
    "# sampled_s = sampled_sub.mask(depth_mask, collapse=True)\n",
    "\n",
    "# --- End of structural‐depth‐driven block ---\n",
    "\n",
    "\n",
    "#[TODO] replace the sampling loop above with the following:\n",
    "# Also remember to implement dataprocessing and the model such that it can take in depth information d\n",
    "\n",
    "# For each sampled piece with noisy nodes:\n",
    "# For each edge type of depth d, itterating from max(d) to min(d)\n",
    "\n",
    "# 1. Get only the nodes that are connected by structural edges of depth d from the last column of the R tensor\n",
    "# 2. Use it to create a noisy subgraph defined by X', E', R'. If X', E', R' already exists, append the new nodes and edges to it\n",
    "# 3. Feed X', E', R' into the Diffusion model with num_diff_step_d steps\n",
    "# 4. Save the resulting graph as X', E', R'\n",
    "# 5. Repeat until all nodes and edges in the original graph has been added\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, _, y = sampled_s.X, sampled_s.E, sampled_s.y\n",
    "\n",
    "E, _ = loaded_model.apply_node_mask_E_r(E,r, node_mask)\n",
    "\n",
    "# Prepare the chain for saving\n",
    "if keep_chain > 0:\n",
    "    final_X_chain = X[:keep_chain]\n",
    "    final_E_chain = E[:keep_chain]\n",
    "\n",
    "    chain_X[0] = final_X_chain                  # Overwrite last frame with the resulting X, E\n",
    "    chain_E[0] = final_E_chain\n",
    "\n",
    "    chain_X = diffusion_utils.reverse_tensor(chain_X)\n",
    "    chain_E = diffusion_utils.reverse_tensor(chain_E)\n",
    "\n",
    "    # Repeat last frame to see final sample better\n",
    "    chain_X = torch.cat([chain_X, chain_X[-1:].repeat(10, 1, 1)], dim=0)\n",
    "    chain_E = torch.cat([chain_E, chain_E[-1:].repeat(10, 1, 1, 1)], dim=0)\n",
    "    assert chain_X.size(0) == (number_chain_steps + 10)\n",
    "\n",
    "molecule_list = []\n",
    "for i in range(batch_size):\n",
    "    n = n_nodes[i]\n",
    "    atom_types = X[i, :n].cpu()\n",
    "    edge_types = E[i, :n, :n].cpu()\n",
    "    rhythm_types = r[i, :n, :].cpu()\n",
    "    sample_names = names[i]\n",
    "    molecule_list.append([atom_types, edge_types, rhythm_types, sample_names])\n",
    "\n",
    "# Visualize chains\n",
    "# if loaded_model.visualization_tools is not None:\n",
    "#     loaded_model.print('Visualizing chains...')\n",
    "#     current_path = os.getcwd()\n",
    "#     num_molecules = chain_X.size(1)       # number of molecules\n",
    "#     for i in range(num_molecules):\n",
    "#         result_path = os.path.join(current_path, f'chains/{loaded_model.cfg.general.name}/'\n",
    "#                                                     f'epoch{loaded_model.current_epoch}/')\n",
    "#         if not os.path.exists(result_path):\n",
    "#             os.makedirs(result_path)\n",
    "#             _ = loaded_model.visualization_tools.visualize_chain(result_path,\n",
    "#                                                             chain_X[:, i, :].numpy(),\n",
    "#                                                             chain_E[:, i, :].numpy())\n",
    "#         loaded_model.print('\\r{}/{} complete'.format(i+1, num_molecules), end='', flush=True)\n",
    "#     loaded_model.print('\\nVisualizing molecules...')\n",
    "\n",
    "#     # Visualize the final molecules \n",
    "#     result_path = os.path.join(current_path,\n",
    "#                                 f'graphs/{loaded_model.name}/epoch{loaded_model.current_epoch}/')\n",
    "#     loaded_model.visualization_tools.visualize(result_path, molecule_list, save_final)\n",
    "#     loaded_model.print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([ 9, 14, 11,  2,  7, 14, 11, 12,  2,  2,  7, 15,  9,  9,  2,  2, 11, 11,\n",
       "          12,  9, 11, 15, 12,  9, 11, 15, 11,  2,  2,  9,  2, 15, 12,  9, 14,  2,\n",
       "          11,  2, 14, 14, 15, 15, 12,  7, 11, 15, 12, 12,  7, 15, 12,  9,  2, 12,\n",
       "          12,  7, 14, 15, 11, 11,  7, 12,  2, 15,  9, 12, 12, 15, 12,  2, 14,  9,\n",
       "          15,  2, 12,  9, 12, 14, 14, 12, 12,  2,  2, 12, 14, 14,  2,  2,  7, 12,\n",
       "          15,  9,  7, 11, 12,  9, 12,  2,  9, 15,  2,  7,  9,  9,  2,  2,  2,  9,\n",
       "           9,  2, 11, 11, 11, 12,  2,  7, 11, 14, 11,  7,  2,  9,  9,  2,  2,  2,\n",
       "           2,  2,  9,  2]),\n",
       "  tensor([[0, 0, 1,  ..., 0, 0, 0],\n",
       "          [0, 0, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          [0, 0, 0,  ..., 1, 0, 0]]),\n",
       "  tensor([[1.0000, 0.0000, 0.0000,  ..., 0.3333, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 1.0000,  ..., 0.3333, 0.0000, 0.0000],\n",
       "          [0.0000, 1.0000, 0.0000,  ..., 0.3333, 0.0175, 0.1429],\n",
       "          ...,\n",
       "          [1.0000, 0.0000, 0.0000,  ..., 0.6667, 0.9649, 0.8571],\n",
       "          [0.0000, 1.0000, 0.0000,  ..., 1.0000, 1.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]),\n",
       "  '../../../SchenkerDiff/schenkerian_clusters/Chorale_206/Chorale_206']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecule_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated graphs Saved. Computing sampling metrics...\n"
     ]
    }
   ],
   "source": [
    "samples = molecule_list\n",
    "filename = f'generated_samples1.txt'\n",
    "\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    for item in samples:\n",
    "        f.write(f\"N={item[0].shape[0]}\\n\")\n",
    "        atoms = item[0].tolist()\n",
    "        f.write(\"X: \\n\")\n",
    "        for at in atoms:\n",
    "            f.write(f\"{at} \")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"E: \\n\")\n",
    "        for bond_list in item[1]:\n",
    "            for bond in bond_list:\n",
    "                f.write(f\"{int(bond)} \")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"R: \\n\")\n",
    "        for r_list in item[2]:\n",
    "            for r in r_list:\n",
    "                f.write(f\"{r} \")\n",
    "            f.write(\"\\n\")\n",
    "        for name in item[3]:\n",
    "            f.write(name)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "print(\"Generated graphs Saved. Computing sampling metrics...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
